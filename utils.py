# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15WMXmeJBSsHFt5UtQXUG4QO3nbj7vvkm
"""

import os
import cv2
import glob
import h5py
import random
import matplotlib.pyplot as plt
import tensorflow as tf
import scipy.ndimage
from skimage import transform,data
from scipy.ndimage import filters
from PIL import Image  
from skimage import exposure
import scipy.misc
import scipy.ndimage
import numpy as np
import tensorflow as tf
import imageio

FLAGS = tf.app.flags.FLAGS

def read_data(path):
  with h5py.File(path, 'r') as hf:  
    data = np.array(hf.get('data'))
    label = np.array(hf.get('label'))
    return data, label

def preprocess(path, scale=3):



  scale-=1
  image=imageio.imread(path, pilmode='YCbCr').astype(np.float)
  image=modcrop(image , scale)
  label_=image[:,:,0]
 
  image = image/255.
  label_ = label_/255.
  input_ = scipy.ndimage.interpolation.zoom(label_, (1./(scale)),mode='wrap',prefilter=False) 
  input_ = scipy.ndimage.interpolation.zoom(input_, ((scale)/1.),mode='wrap',prefilter=False)
  label_small=modcrop_small(label_)
  input_small=modcrop_small(input_)
  
  return input_, label_

def prepare_data(sess, dataset):
  if FLAGS.is_train:
    filenames = os.listdir(dataset)
    data_dir = os.path.join(os.getcwd(), dataset)
    data = glob.glob(os.path.join(data_dir, "*.png"))
  else:
    data_dir = os.path.join((os.path.join(os.getcwd(), dataset)),"Set5")
    data = glob.glob(os.path.join(data_dir,"*.png"))
  return data

def make_data(sess, data, label):
  if FLAGS.is_train:
    savepath = os.path.join(os.getcwd(), 'checkpoint/train.h5')
  else:
    savepath = os.path.join(os.getcwd(), 'checkpoint/test.h5')
  with h5py.File(savepath, 'w') as hf:
    hf.create_dataset('data', data=data)
    hf.create_dataset('label', data=label)

def imread(path, is_grayscale=True):
  if is_grayscale:
    return imageio.imread(path, flatten=True, pilmode='YCbCr').astype(np.float)
  else:
    return imageio.imread(path, pilmode='YCbCr').astype(np.float)

# In convolution process, border part of image will be cut off. So I extra add a layer of zeros in the border of my original image.
# Every original image resolution is 255*255 pixel
def modcrop(image, scale=3):
  if len(image.shape) == 3:
    h, w, _ = image.shape
    np2 = np.zeros([265,265,3])
    image = image[0:h, 0:w]
    np2[5:260,5:260] = image
 
  else:
    h, w, _ = image.shape
    np2 = np.zeros([265,265,3])
    image = image[0:h, 0:w]
    np2[5:260,5:260] = image
  
  return np2

# Convolution Caculate
# Separate 255*255 pixel image into N 33*33 pixel sub-image
# After convolution caculate, 21*21 piel sub-image will stack to 252*252 SRCNN image.(merge)
def modcrop_small(image):
  
  padding2 = 6
  
  if len(image.shape) == 3:
    h, w, _ = image.shape
    h =(h-33+1)//21*21+21+padding2   
    w =(w-33+1)//21*21+21+padding2     
    image1 = image[padding2:h, padding2:w, :]     
  else:
    h, w = image.shape
    h =(h-33+1)//21*21+21+padding2     
    w =(w-33+1)//21*21+21+padding2    
    image1 = image[padding2:h, padding2:w]
  return image1

def input_setup(sess, config):
  
  # Start to read training and testing file
  if config.is_train:
    data = prepare_data(sess, dataset="train")
    print(len(data))
  else:
    data = prepare_data(sess, dataset="test")
    print(len(data))
    
  sub_input_sequence = []
  sub_label_sequence = []
  padding = abs(config.image_size - config.label_size) // 2
  
  # Padding caculate
  
  if config.is_train: 
    for i in range(len(data)):
      input_, label_ = preprocess(data[i], config.scale)
      if len(input_.shape) == 3:
        h, w, _ = input_.shape
      else:
        h, w = input_.shape
      
      for x in range(0, h-config.image_size+1, config.stride):
        for y in range(0, w-config.image_size+1, config.stride):
          sub_input = input_[x:x+config.image_size, y:y+config.image_size] 
          sub_label = label_[x+padding:x+padding+config.label_size, y+padding:y+padding+config.label_size] 
          sub_input = sub_input.reshape([config.image_size, config.image_size, 1])
          sub_label = sub_label.reshape([config.label_size, config.label_size, 1])
          sub_input_sequence.append(sub_input)
          sub_label_sequence.append(sub_label)
  else:
        
        input_, label_ = preprocess(data[0], config.scale)
        if len(input_.shape) == 3:
          h, w, _ = input_.shape
        else:
          h, w = input_.shape
        nx = 0 
        ny = 0 
        
        for x in range(0, h-config.image_size+1, config.stride): 
          nx += 1
          ny = 0
          for y in range(0, w-config.image_size+1, config.stride):
            ny += 1
            
            sub_input = input_[x:x+config.image_size, y:y+config.image_size] # [33 x 33]
            sub_label = label_[x+padding:x+padding+config.label_size, y+padding:y+padding+config.label_size] # [21 x 21] 
            sub_input = sub_input.reshape([config.image_size, config.image_size, 1])  
            sub_label = sub_label.reshape([config.label_size, config.label_size, 1])
            sub_input_sequence.append(sub_input)
            sub_label_sequence.append(sub_label)
  
  arrdata = np.asarray(sub_input_sequence) 
  arrlabel = np.asarray(sub_label_sequence) 
  make_data(sess, arrdata, arrlabel)
  if not config.is_train:
    return nx, ny
  
  # important

def imsave(image, path):
  return imageio.imsave(path, image)

def merge(images, size):
  h, w = images.shape[1], images.shape[2] 
  img = np.zeros((h*size[0], w*size[1], 1))
  
  for idx, image in enumerate(images):
    i = idx % size[1]
    j = idx // size[1]
    img[j*h:j*h+h, i*w:i*w+w, :] = image
  return img